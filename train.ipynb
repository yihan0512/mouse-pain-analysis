{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c62f58ad-2885-4b10-95af-07e40d207ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yi/anaconda3/envs/pain/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import multiprocessing\n",
    "import os\n",
    "import random\n",
    "\n",
    "# from google.colab import drive\n",
    "import h5py\n",
    "# not used in DeepEthogram; only to easily show plots\n",
    "from IPython.display import Image\n",
    "from omegaconf import OmegaConf\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from deepethogram import configuration, postprocessing, projects, utils\n",
    "from deepethogram.debug import print_dataset_info\n",
    "from deepethogram.flow_generator.train import flow_generator_train\n",
    "from deepethogram.feature_extractor.train import feature_extractor_train\n",
    "from deepethogram.feature_extractor.inference import feature_extractor_inference\n",
    "from deepethogram.sequence.train import sequence_train\n",
    "from deepethogram.sequence.inference import sequence_inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c05e2585-acf5-4f63-a66b-febc76a0fcd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.1\n",
      "gpu available: True\n",
      "gpu name: NVIDIA RTX A5000\n"
     ]
    }
   ],
   "source": [
    "# Make sure we actually have a GPU\n",
    "print(torch.__version__)\n",
    "print('gpu available: {}'.format(torch.cuda.is_available()))\n",
    "print('gpu name: {}'.format(torch.cuda.get_device_name(0)))\n",
    "\n",
    "assert torch.cuda.is_available(), 'Please select a GPU runtime and then restart!'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00296939-9722-4c1d-bc3d-34b61fbc3d54",
   "metadata": {},
   "source": [
    "## set project path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b9dadff-eb2a-4a33-960a-26f95f826fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_path = '/home/yi/Sunze/mouse_pain_4_deepethogram'\n",
    "files = os.listdir(project_path)\n",
    "assert 'DATA' in files, 'DATA directory not found! {}'.format(files)\n",
    "assert 'models' in files, 'models directory not found! {}'.format(files)\n",
    "assert 'project_config.yaml' in files, 'project config not found! {}'.format(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5267b553-673f-453f-a2ab-953d631a3fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_logger():\n",
    "  # First, overwrite any logger so that we can actually see log statements\n",
    "  # https://stackoverflow.com/questions/13839554/how-to-change-filehandle-with-python-logging-on-the-fly-with-different-classes-a\n",
    "  log = logging.getLogger()  # root logger\n",
    "  log.setLevel(logging.INFO)\n",
    "  for hdlr in log.handlers[:]:  # remove all old handlers\n",
    "      log.removeHandler(hdlr)\n",
    "  log.addHandler(logging.StreamHandler())\n",
    "  return log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb9c33b-c729-480d-832e-b842857069d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "log = reset_logger()\n",
    "\n",
    "print_dataset_info(os.path.join(project_path, 'DATA'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b362374-652e-4420-85cf-8498f24ffb64",
   "metadata": {},
   "source": [
    "## train and evaluate flow generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cfd7d145-e3c6-46fd-8feb-bc97a67ec336",
   "metadata": {},
   "outputs": [],
   "source": [
    "preset = 'deg_f'\n",
    "cfg = configuration.make_flow_generator_train_cfg(project_path, preset=preset)\n",
    "# print(OmegaConf.to_yaml(cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f2645e9-61ba-4cf6-91c2-abbc1adf4066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n cpus: 32\n"
     ]
    }
   ],
   "source": [
    "n_cpus = multiprocessing.cpu_count()\n",
    "\n",
    "print('n cpus: {}'.format(n_cpus))\n",
    "cfg.compute.num_workers = n_cpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306cf484-031e-46f4-b8e0-df371264077d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "flow_generator = flow_generator_train(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad12ff9-ec6f-4366-beac-34980328cf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join(project_path, 'models')\n",
    "weights = projects.get_weights_from_model_path(model_path)\n",
    "flow_weights = weights['flow_generator']\n",
    "# because we used deg_f, our model type is a TinyMotionNet\n",
    "latest_weights = flow_weights['TinyMotionNet'][-1]\n",
    "# our run directory is two steps above the weight file\n",
    "run_dir = os.path.dirname(os.path.dirname(latest_weights))\n",
    "assert os.path.isdir(run_dir), 'run directory not found! {}'.format(run_directory)\n",
    "\n",
    "figure_dir = os.path.join(run_dir, 'figures')\n",
    "figure_files = utils.get_subfiles(figure_dir, 'file')\n",
    "assert len(figure_files) == 1\n",
    "\n",
    "Image(figure_files[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a15059-1631-4465-8cef-5c332ac33202",
   "metadata": {},
   "source": [
    "## train and evaluate feature extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e81fbbd3-167b-4519-90dd-c20b34a93b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "preset = 'deg_f'\n",
    "cfg = configuration.make_feature_extractor_train_cfg(project_path, preset=preset)\n",
    "# print(OmegaConf.to_yaml(cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7cfdb753-14bd-4b54-9973-af8e06791e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the latest string will find the most recent model by date\n",
    "# you can also pass a specific .pt or .ckpt file here\n",
    "cfg.flow_generator.weights = 'latest'\n",
    "cfg.compute.num_workers = n_cpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303f3c35-8c26-4b9c-a92f-a9a28bcbe79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "log = reset_logger()\n",
    "\n",
    "feature_extractor = feature_extractor_train(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b9b1b7-67d8-4288-a6fa-60fe9b7eac86",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join(project_path, 'models')\n",
    "weights = projects.get_weights_from_model_path(model_path)\n",
    "flow_weights = weights['feature_extractor']\n",
    "# because we used deg_f, our model type is a resnet18\n",
    "latest_weights = flow_weights['resnet18'][-1]\n",
    "# our run directory is two steps above the weight file\n",
    "run_dir = os.path.dirname(os.path.dirname(latest_weights))\n",
    "assert os.path.isdir(run_dir), 'run directory not found! {}'.format(run_directory)\n",
    "\n",
    "figure_dir = os.path.join(run_dir, 'figures')\n",
    "figure_files = utils.get_subfiles(figure_dir, 'file')\n",
    "assert len(figure_files) >= 1\n",
    "\n",
    "Image(figure_files[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c43a13e-7bf0-4d6c-a9da-c08d6beb64ae",
   "metadata": {},
   "source": [
    "## run inference on feature extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0a04147a-cb36-427d-a561-386a7b894f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = configuration.make_feature_extractor_inference_cfg(project_path=project_path, preset=preset)\n",
    "# print(OmegaConf.to_yaml(cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "294cd101-ef6f-4513-8a4f-a2f3390421e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.feature_extractor.weights = 'latest'\n",
    "cfg.flow_generator.weights = 'latest'\n",
    "\n",
    "cfg.inference.overwrite = True\n",
    "# make sure errors are thrown\n",
    "cfg.inference.ignore_error = False\n",
    "cfg.compute.num_workers = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc0047a-b80c-4f28-8af4-ae7be93a13cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_extractor_inference(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a8e9ada2-5c2a-4d20-92b8-5d568ad1d2ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet18\n",
      "|--- P: (30000, 5) float32\n",
      "|--- class_names: (5,) object\n",
      "|--- flow_features: (30000, 512) float32\n",
      "|--- logits: (30000, 5) float32\n",
      "|--- spatial_features: (30000, 512) float32\n",
      "|--- thresholds: (5,) float32\n",
      "attrs: \n"
     ]
    }
   ],
   "source": [
    "# this just parses our DATA directory, to get the path to each file for each video\n",
    "records = projects.get_records_from_datadir(os.path.join(project_path, 'DATA'))\n",
    "animal = random.choice(list(records.keys()))\n",
    "record = records[animal]\n",
    "\n",
    "# I call the file output by inference the `outputfile` in various places in the code\n",
    "outputfile = record['output']\n",
    "\n",
    "utils.print_hdf5(outputfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9e16b7f7-3f4f-45bd-b46d-22239048ddac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.99963176, 0.00010334, 0.00058106, 0.0005716 , 0.00026475],\n",
       "       [0.9997664 , 0.00007283, 0.00033909, 0.00107767, 0.00014999],\n",
       "       [0.99962926, 0.00007196, 0.00032246, 0.00106743, 0.00019711],\n",
       "       ...,\n",
       "       [0.9986204 , 0.00026089, 0.0002461 , 0.00188831, 0.00020759],\n",
       "       [0.99916863, 0.00016259, 0.00021173, 0.00226606, 0.00011618],\n",
       "       [0.99795157, 0.00061912, 0.00027724, 0.00201472, 0.00022794]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we use the h5py package for this\n",
    "with h5py.File(outputfile, 'r') as f:\n",
    "  probabilities = f['resnet18/P'][:]\n",
    "# n frames x K behaviors\n",
    "print(probabilities.shape)\n",
    "probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b5c3e0-7bf1-4475-a501-34b3ef6471ae",
   "metadata": {},
   "source": [
    "## train and evaluate sequence model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7dc8614e-e6e8-40f7-9c0b-c74be9b4d4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = configuration.make_sequence_train_cfg(project_path=project_path)\n",
    "cfg.compute.num_workers = n_cpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2747cf-3851-4cb4-beb4-d35a6e97ee05",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_model = sequence_train(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0305ff80-75ea-479a-a135-b314e349c6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join(project_path, 'models')\n",
    "weights = projects.get_weights_from_model_path(model_path)\n",
    "sequence_weights = weights['sequence']\n",
    "# bthe sequence type is always tgmj, a slightly modified TGM model\n",
    "latest_weights = sequence_weights['tgmj'][-1]\n",
    "# our run directory is two steps above the weight file\n",
    "run_dir = os.path.dirname(os.path.dirname(latest_weights))\n",
    "assert os.path.isdir(run_dir), 'run directory not found! {}'.format(run_directory)\n",
    "\n",
    "figure_dir = os.path.join(run_dir, 'figures')\n",
    "figure_files = utils.get_subfiles(figure_dir, 'file')\n",
    "assert len(figure_files) >= 1\n",
    "\n",
    "Image(figure_files[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713c2381-ecbf-4252-b72a-e3d0a6a11b4f",
   "metadata": {},
   "source": [
    "## sequence inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d286fae-91de-45e1-bdf9-2d6e1c824a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = configuration.make_sequence_inference_cfg(project_path)\n",
    "cfg.sequence.weights = 'latest'\n",
    "cfg.compute.num_workers = n_cpus\n",
    "cfg.inference.overwrite = True\n",
    "cfg.inference.ignore_error = False\n",
    "\n",
    "sequence_inference(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e70aeca8-68bb-473a-aa69-05f416cc9a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet18\n",
      "|--- P: (30000, 5) float32\n",
      "|--- class_names: (5,) object\n",
      "|--- flow_features: (30000, 512) float32\n",
      "|--- logits: (30000, 5) float32\n",
      "|--- spatial_features: (30000, 512) float32\n",
      "|--- thresholds: (5,) float32\n",
      "tgmj\n",
      "|--- P: (30000, 5) float32\n",
      "|--- class_names: (5,) object\n",
      "|--- logits: (30000, 5) float32\n",
      "|--- thresholds: (5,) float32\n",
      "attrs: \n"
     ]
    }
   ],
   "source": [
    "# this just parses our DATA directory, to get the path to each file for each video\n",
    "records = projects.get_records_from_datadir(os.path.join(project_path, 'DATA'))\n",
    "animal = random.choice(list(records.keys()))\n",
    "record = records[animal]\n",
    "\n",
    "# I call the file output by inference the `outputfile` in various places in the code\n",
    "outputfile = record['output']\n",
    "\n",
    "utils.print_hdf5(outputfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "78ad29e8-215e-4e9f-af94-b3e33474ba5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 5)\n",
      "[0.01       0.5        0.5        0.37694675 0.03024774]\n"
     ]
    }
   ],
   "source": [
    "# we use the h5py package for this\n",
    "with h5py.File(outputfile, 'r') as f:\n",
    "  probabilities = f['tgmj/P'][:]\n",
    "  thresholds = f['tgmj/thresholds'][:]\n",
    "# n frames x K behaviors\n",
    "print(probabilities.shape)\n",
    "print(thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1e54a5c1-06bd-4592-98de-43ad1716ea50",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = configuration.make_postprocessing_cfg(project_path=project_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cf6c710b-6853-4ee1-9f1f-7b5ce020d1e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-09-18 00:20:45,294] INFO [deepethogram.projects.convert_config_paths_to_absolute:1135] cwd in absolute: /home/yi/Sunze/mouse_pain_4_deepethogram/models/220918_001755_sequence_inference\n",
      "[2022-09-18 00:20:45,295] INFO [deepethogram.projects.convert_config_paths_to_absolute:1178] after absolute: {'class_names': ['background', 'left_hindpaw_biting/licking', 'right_hindpaw_biting/licking', 'genital_licking', 'bout_of_hindpaw_scratchingandbiting'], 'config_file': '/home/yi/Sunze/mouse_pain_4_deepethogram/project_config.yaml', 'data_path': '/home/yi/Sunze/mouse_pain_4_deepethogram/DATA', 'labeler': None, 'model_path': '/home/yi/Sunze/mouse_pain_4_deepethogram/models', 'name': 'mouse_pain_4', 'path': '/home/yi/Sunze/mouse_pain_4_deepethogram', 'pretrained_path': '/home/yi/Sunze/mouse_pain_4_deepethogram/models/pretrained_models'}\n"
     ]
    }
   ],
   "source": [
    "postprocessing.postprocess_and_save(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "73a8738d-5fb9-44b4-9ac9-26f096f9426d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>background</th>\n",
       "      <th>left_hindpaw_biting/licking</th>\n",
       "      <th>right_hindpaw_biting/licking</th>\n",
       "      <th>genital_licking</th>\n",
       "      <th>bout_of_hindpaw_scratchingandbiting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   background  left_hindpaw_biting/licking  right_hindpaw_biting/licking  \\\n",
       "0           1                            0                             0   \n",
       "1           1                            0                             0   \n",
       "2           1                            0                             0   \n",
       "3           1                            0                             0   \n",
       "4           1                            0                             0   \n",
       "\n",
       "   genital_licking  bout_of_hindpaw_scratchingandbiting  \n",
       "0                0                                    0  \n",
       "1                0                                    0  \n",
       "2                0                                    0  \n",
       "3                0                                    0  \n",
       "4                0                                    0  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load a random record\n",
    "records = projects.get_records_from_datadir(os.path.join(project_path, 'DATA'))\n",
    "animal = random.choice(list(records.keys()))\n",
    "record = records[animal]\n",
    "# figure out the filename\n",
    "predictions_filename = os.path.join(os.path.dirname(record['rgb']), record['key'] + '_predictions.csv')\n",
    "assert os.path.isfile(predictions_filename)\n",
    "\n",
    "# read csv\n",
    "df = pd.read_csv(predictions_filename, index_col=0)\n",
    "# display outputs\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
